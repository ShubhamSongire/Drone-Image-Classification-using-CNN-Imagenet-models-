{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e44ed9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-362b239f7878>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmysql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mschedule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mysql'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "import schedule\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.setrecursionlimit(20000)\n",
    "\n",
    "index = 1\n",
    "store = []\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "eachInfo = ()\n",
    "\n",
    "# connect the mysql\n",
    "mydb = mysql.connector.connect(\n",
    "    host=\"cryptomoist.com\",        \n",
    "    user=\"cryptist\",\n",
    "    password=\"4RbmAc2AyLj9MlL7\",\n",
    "    database=\"cryptist_testcoins\"\n",
    ")\n",
    "mycursor = mydb.cursor()\n",
    "sql = \"INSERT INTO coin %s, %s, %s, %s\" % (name, watchlist, dates, img)\n",
    "\n",
    "def findElement(url):\n",
    "    global index, store, today, eachInfo\n",
    "    r = requests.get(url)\n",
    "    coinPage = BeautifulSoup(r.content)\n",
    "    panel = coinPage.find('div', { 'class': 'sc-16r8icm-0' and 'kDzKwW' and 'nameSection' })\n",
    "    if panel is not None:\n",
    "        img = panel.find('img').attrs['src']                \n",
    "        coinNameDup = panel.find('h2').text.strip()\n",
    "        alias = panel.find('small').text.strip()\n",
    "        coinName = coinNameDup[slice(len(coinNameDup)-len(alias))]\n",
    "        namePill = panel.find_all('div', { 'class': 'namePill' })\n",
    "        watchlist = namePill[2].text\n",
    "        watchlist = watchlist[2:-10].replace(',','').strip()\n",
    "        watchlist = int(watchlist)\n",
    "        eachInfo = (coinName, watchlist, today, img)\n",
    "        store.append(eachInfo) \n",
    "        \n",
    "        print(index, coinName, watchlist, img)\n",
    "    else:        \n",
    "        findElement(url)\n",
    "\n",
    "def insertDb():\n",
    "    global mydb, mycursor, sql, eachInfo\n",
    "\n",
    "    if mydb.is_connected():\n",
    "        mycursor.execute(sql, eachInfo)\n",
    "        mydb.commit()\n",
    "    else:\n",
    "        insertDb()\n",
    "\n",
    "def scraping():\n",
    "    global index, store, eachInfo    \n",
    "\n",
    "    scrap_url = \"https://coinmarketcap.com\"\n",
    "    origin_url = \"https://coinmarketcap.com\"  \n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        req = requests.get(scrap_url)\n",
    "        time.sleep(1)\n",
    "        source = BeautifulSoup(req.content)        \n",
    "\n",
    "        content = source.find('div', { 'class': 'h7vnx2-1 bFzXgL' })\n",
    "        table = content.find('table', { 'class': 'h7vnx2-2' and 'czTsgW' and 'cmc-table' })\n",
    "        tbody = table.find('tbody')\n",
    "        coins = tbody.find_all('tr')\n",
    "\n",
    "        for coin in coins:\n",
    "            coinInfo = coin.find('a')\n",
    "            coinUrl = origin_url + coinInfo['href']\n",
    "            findElement(coinUrl)\n",
    "            insertDb()\n",
    "            # mycursor.execute(sql, eachInfo)\n",
    "            # mydb.commit()\n",
    "\n",
    "            index = index + 1\n",
    "\n",
    "        # if index >= 100:\n",
    "        #     break\n",
    "\n",
    "        time.sleep(1)\n",
    "        paginateDiv = source.find('div', { 'class': 'sc-16r8icm-0' and 'sc-4r7b5t-0' and 'gJbsQH' })\n",
    "        ul = paginateDiv.find('ul', { 'class': 'pagination' })\n",
    "        li = ul.find('li', { 'class': 'next' })\n",
    "        if li.find('a').has_attr('href'):\n",
    "            nextUrl = li.find('a').attrs['href']\n",
    "            scrap_url = origin_url + nextUrl\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #insert the datas to mysql\n",
    "    # try:\n",
    "    # mycursor.executemany(sql, store)\n",
    "    # mydb.commit()\n",
    "    print(\"Datas are inserted successfully!\")\n",
    "    print(\"Waiting next day...\")\n",
    "    # except:\n",
    "    #     mydb.rollback()\n",
    "# scraping()\n",
    "schedule.every().day.at(\"16:52\").do(scraping)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
